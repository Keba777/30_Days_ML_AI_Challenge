# Day 06: Model Evaluation

## What I Learned
- **Train-Test Split**:
  - The importance of separating data into training and testing sets.
  - Avoiding data leakage to ensure unbiased evaluation.
- **Cross-Validation**:
  - Understanding k-fold cross-validation for robust model evaluation.
  - Balancing bias and variance by varying folds.
- **Confusion Matrix**:
  - Interpreting the confusion matrix and its components (TP, FP, FN, TN).
  - Visualizing the confusion matrix to assess classification performance.

## Tasks Completed
1. **Evaluation of Day 5 Model**:
   - Split data into training and testing sets for fair evaluation.
   - Applied cross-validation to improve model performance.
   - Visualized the confusion matrix for better insights.
2. **Model Improvement**:
   - Experimented with different values of `K` in KNN to enhance accuracy.
   - Analyzed how evaluation metrics change with model parameters.

## Resources Used
- [Scikit-learn Train-Test Split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)
- [K-Fold Cross-Validation](https://machinelearningmastery.com/k-fold-cross-validation/)
- [Scikit-learn Confusion Matrix Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)
- [Understanding the Confusion Matrix](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62)
- [KNN Hyperparameter Tuning](https://towardsdatascience.com/knn-hyperparameter-tuning-in-scikit-learn-6a34b3f3c210)
